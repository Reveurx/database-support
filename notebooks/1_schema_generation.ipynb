{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ec1c1b-a26e-47f7-b409-edfb50ca23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт всех необходимых библиотек\n",
    "# !pip install pandas openpyxl lxml matplotlib networkx graphviz sqlalchemy psycopg2-binary\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from sqlalchemy import create_engine, Integer, SmallInteger, String, Text, DateTime, Date, Boolean, Float\n",
    "from sqlalchemy.dialects.postgresql import UUID\n",
    "from sqlalchemy import create_engine\n",
    "from graphviz import Digraph\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8825ca-7988-47f2-95d5-54fb0cbfa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсинг Excel схемы\n",
    "excel_path = r\"C:\\ваш\\путь\\к_проекту\\tables_specification.xlsx\" # Заменить на путь, куда загружен файл из data\n",
    "xls = pd.read_excel(excel_path, sheet_name=None, header=None)\n",
    "\n",
    "parsed_rows = []\n",
    "\n",
    "current_table = None\n",
    "parsing_fields = False\n",
    "field_definitions = []\n",
    "primary_keys = set()\n",
    "foreign_keys_map = {}\n",
    "\n",
    "for sheet_name, df in xls.items():\n",
    "    for idx, row in df.iterrows():\n",
    "        col_a = str(row[0]) if pd.notna(row[0]) else \"\"\n",
    "        col_b = str(row[1]) if pd.notna(row[1]) else \"\"\n",
    "        col_c = str(row[2]) if pd.notna(row[2]) else \"\"\n",
    "\n",
    "        if col_a.startswith(\"Table \"):\n",
    "            if current_table and field_definitions:\n",
    "                for field in field_definitions:\n",
    "                    field_name = field[\"Field Name\"]\n",
    "                    parsed_rows.append({\n",
    "                        \"Table\": current_table,\n",
    "                        \"Field Name\": field_name,\n",
    "                        \"Data Type\": field[\"Data Type\"],\n",
    "                        \"Indexed\": field[\"Indexed\"],\n",
    "                        \"Primary Key\": field_name in primary_keys,\n",
    "                        \"Foreign Key\": foreign_keys_map.get(field_name)\n",
    "                    })\n",
    "            current_table = col_a.replace(\"Table \", \"\").strip()\n",
    "            parsing_fields = False\n",
    "            field_definitions = []\n",
    "            primary_keys = set()\n",
    "            foreign_keys_map = {}\n",
    "            continue\n",
    "\n",
    "        if \"Field Name\" in col_b:\n",
    "            parsing_fields = True\n",
    "            continue\n",
    "\n",
    "        if col_a.strip() in {\"Indexes\", \"Foreign Keys\"}:\n",
    "            parsing_fields = False\n",
    "            continue\n",
    "\n",
    "        if col_b.strip() == \"Primary\" and col_c.startswith(\"ON \"):\n",
    "            pk = col_c.replace(\"ON\", \"\").strip()\n",
    "            primary_keys.add(pk)\n",
    "            continue\n",
    "\n",
    "        if col_b.startswith(\"Fk_\") and \"ref\" in col_c:\n",
    "            match = re.match(r\"\\(\\s*(\\w+)\\s*\\)\\s*ref\\s+(\\w+)\\s*\\((\\w+)\\)\", col_c)\n",
    "            if match:\n",
    "                local_col, ref_table, ref_col = match.groups()\n",
    "                foreign_keys_map[local_col] = f\"{ref_table}({ref_col})\"\n",
    "            continue\n",
    "\n",
    "        if parsing_fields and col_b and col_c:\n",
    "            field_definitions.append({\n",
    "                \"Field Name\": col_b,\n",
    "                \"Data Type\": col_c,\n",
    "                \"Indexed\": col_a.strip() == \"*\"\n",
    "            })\n",
    "\n",
    "if current_table and field_definitions:\n",
    "    for field in field_definitions:\n",
    "        field_name = field[\"Field Name\"]\n",
    "        parsed_rows.append({\n",
    "            \"Table\": current_table,\n",
    "            \"Field Name\": field_name,\n",
    "            \"Data Type\": field[\"Data Type\"],\n",
    "            \"Indexed\": field[\"Indexed\"],\n",
    "            \"Primary Key\": field_name in primary_keys,\n",
    "            \"Foreign Key\": foreign_keys_map.get(field_name)\n",
    "        })\n",
    "\n",
    "excel_schema_df = pd.DataFrame(parsed_rows)\n",
    "\n",
    "# Схема XML\n",
    "xml_dirs = [\n",
    "    r\"C:\\ваш\\путь\\к_проекту\\dba.meta.stackexchange.com\", # Заменить на путь, куда загружен и распакован файл из data\n",
    "    r\"C:\\ваш\\путь\\к_проекту\\dba.stackexchange.com\" # Заменить на путь, куда загружен и распакован файл из data\n",
    "]\n",
    "\n",
    "def parse_xml_to_df(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        data = [row.attrib for row in root.findall('row')]\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "xml_tables_data = {}\n",
    "xml_schema = {}\n",
    "\n",
    "for xml_dir in xml_dirs:\n",
    "    for filename in os.listdir(xml_dir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            table_name = os.path.splitext(filename)[0]\n",
    "            file_path = os.path.join(xml_dir, filename)\n",
    "            df = parse_xml_to_df(file_path)\n",
    "            if table_name not in xml_tables_data:\n",
    "                xml_tables_data[table_name] = df\n",
    "            else:\n",
    "                xml_tables_data[table_name] = pd.concat([xml_tables_data[table_name], df], ignore_index=True)\n",
    "\n",
    "for table_name, df in xml_tables_data.items():\n",
    "    xml_schema[table_name] = list(df.columns)\n",
    "\n",
    "xml_rows = []\n",
    "for table, cols in xml_schema.items():\n",
    "    for col in cols:\n",
    "        xml_rows.append({\"Table\": table, \"Field Name\": col})\n",
    "xml_schema_df = pd.DataFrame(xml_rows)\n",
    "\n",
    "# Парсинг basw.txt\n",
    "sql_path = r\"C:\\ваш\\путь\\к_проекту\\sql_queries.txt\" # Заменить на путь, куда загружен файл из data\n",
    "with open(sql_path, encoding='utf-8') as f:\n",
    "    sql_text = f.read()\n",
    "\n",
    "# Убираем комментарии\n",
    "sql_text = re.sub(r'--.*?$', '', sql_text, flags=re.MULTILINE)\n",
    "\n",
    "# Находим все определения таблиц\n",
    "table_defs = re.findall(r'CREATE TABLE\\s+(\\w+)\\s*\\((.*?)\\);', sql_text, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "rows = []\n",
    "for table_name, body in table_defs:\n",
    "    fields = [line.strip().rstrip(',') for line in body.split('\\n') if line.strip()]\n",
    "    primary_keys = []\n",
    "\n",
    "    # Обработка первичных ключей\n",
    "    for line in fields:\n",
    "        if line.upper().startswith(\"PRIMARY KEY\"):\n",
    "            pk_match = re.findall(r'\\((.*?)\\)', line)\n",
    "            if pk_match:\n",
    "                primary_keys = [col.strip().strip('\"') for col in pk_match[0].split(',')]\n",
    "            continue\n",
    "\n",
    "        # Обработка обычных столбцов\n",
    "        match = re.match(r'(\\w+)\\s+([\\w\\(\\)]+)(?:\\s+(NOT NULL|NULL))?', line, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            col_name, col_type, nullability = match.groups()\n",
    "            rows.append({\n",
    "                \"Table\": table_name,\n",
    "                \"Field Name\": col_name,\n",
    "                \"Data Type\": col_type,\n",
    "                \"Nullable\": nullability != \"NOT NULL\",\n",
    "                \"Primary Key\": col_name in primary_keys,\n",
    "                \"Foreign Key\": None,\n",
    "                \"Indexed\": False\n",
    "            })\n",
    "\n",
    "# Обработка внешних ключей\n",
    "foreign_keys = re.findall(\n",
    "    r'ALTER TABLE (\\w+)\\s+ADD CONSTRAINT \\w+\\s+FOREIGN KEY \\(\\s*(\\w+)\\s*\\)\\s+REFERENCES (\\w+)\\s*\\(\\s*(\\w+)\\s*\\)',\n",
    "    sql_text, flags=re.IGNORECASE)\n",
    "\n",
    "for table, field, ref_table, ref_field in foreign_keys:\n",
    "    for row in rows:\n",
    "        if row[\"Table\"] == table and row[\"Field Name\"] == field:\n",
    "            row[\"Foreign Key\"] = f\"{ref_table}({ref_field})\"\n",
    "\n",
    "# Обработка индексов\n",
    "index_defs = re.findall(r'CREATE INDEX ON (\\w+)\\s*\\(\\s*(\\w+)\\s*\\)', sql_text, flags=re.IGNORECASE)\n",
    "for table, field in index_defs:\n",
    "    for row in rows:\n",
    "        if row[\"Table\"] == table and row[\"Field Name\"] == field:\n",
    "            row[\"Indexed\"] = True\n",
    "\n",
    "# Создание DataFrame\n",
    "ddl_df = pd.DataFrame(rows)\n",
    "\n",
    "# Маппинг типов данных из MSSQL в PostgreSQL\n",
    "def convert_mssql_to_pg(mssql_type: str) -> str:\n",
    "    mssql_type = mssql_type.strip().lower()\n",
    "    match = re.match(r'^([a-zA-Z]+)(\\([0-9, ]+\\))?', mssql_type)\n",
    "    if not match:\n",
    "        return 'text'  # запасной вариант\n",
    "\n",
    "    base_type, size = match.groups()\n",
    "    size = size or ''\n",
    "\n",
    "    base_mapping = {\n",
    "        'int': 'integer',\n",
    "        'tinyint': 'smallint',\n",
    "        'smallint': 'smallint',\n",
    "        'bit': 'boolean',\n",
    "        'uniqueidentifier': 'uuid',\n",
    "        'nvarchar': 'varchar',\n",
    "        'varchar': 'varchar',\n",
    "        'datetime': 'timestamp',\n",
    "        'smalldatetime': 'timestamp',\n",
    "        'date': 'date'\n",
    "    }\n",
    "\n",
    "    pg_type = base_mapping.get(base_type, 'text')\n",
    "    if pg_type in {'varchar', 'char', 'numeric'} and size:\n",
    "        return f'{pg_type}{size}'\n",
    "    return pg_type\n",
    "\n",
    "ddl_df[\"Data Type\"] = ddl_df[\"Data Type\"].apply(convert_mssql_to_pg)\n",
    "\n",
    "# Сопоставление и создание финальной схемы\n",
    "excel_schema_df[\"Table_lc\"] = excel_schema_df[\"Table\"].str.lower()\n",
    "ddl_df[\"Table_lc\"] = ddl_df[\"Table\"].str.lower()\n",
    "xml_schema_df[\"Table_lc\"] = xml_schema_df[\"Table\"].str.lower()\n",
    "\n",
    "common_tables = set(excel_schema_df[\"Table_lc\"]).intersection(set(xml_schema_df[\"Table_lc\"]))\n",
    "\n",
    "ordered_schema = []\n",
    "for table in sorted(common_tables):\n",
    "    excel_sub = excel_schema_df[excel_schema_df[\"Table_lc\"] == table]\n",
    "    xml_sub = xml_schema_df[xml_schema_df[\"Table_lc\"] == table]\n",
    "    ddl_sub = ddl_df[ddl_df[\"Table_lc\"] == table]\n",
    "\n",
    "    xml_fields = list(xml_sub[\"Field Name\"])\n",
    "    excel_fields = list(excel_sub[\"Field Name\"])\n",
    "    ddl_fields = list(ddl_sub[\"Field Name\"])\n",
    "\n",
    "    for col in xml_fields:\n",
    "        base_row = excel_sub[excel_sub[\"Field Name\"] == col]\n",
    "        if not base_row.empty:\n",
    "            row = base_row.iloc[0].to_dict()\n",
    "        else:\n",
    "            row = {\n",
    "                \"Table\": excel_sub[\"Table\"].iloc[0],\n",
    "                \"Field Name\": col,\n",
    "                \"Data Type\": \"varchar\" if \"id\" not in col.lower() else \"integer\",\n",
    "                \"Indexed\": False,\n",
    "                \"Primary Key\": False,\n",
    "                \"Foreign Key\": None,\n",
    "                \"Nullable\": True\n",
    "            }\n",
    "\n",
    "        ddl_row = ddl_sub[ddl_sub[\"Field Name\"] == col]\n",
    "        if not ddl_row.empty:\n",
    "            row[\"Data Type\"] = ddl_row[\"Data Type\"].iloc[0]\n",
    "            row[\"Nullable\"] = ddl_row[\"Nullable\"].iloc[0]\n",
    "\n",
    "        ordered_schema.append(row)\n",
    "\n",
    "# Создание финальной схемы\n",
    "final_schema_df = pd.DataFrame(ordered_schema)\n",
    "final_schema_df = final_schema_df[[\"Table\", \"Field Name\", \"Data Type\", \"Indexed\", \"Primary Key\", \"Foreign Key\", \"Nullable\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8cb93-d99a-4882-895e-5be8ba6eca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание визуализации:\n",
    "\n",
    "df = final_schema_df.copy()\n",
    "\n",
    "# Группируем поля по таблицам\n",
    "tables = df['Table'].unique()\n",
    "\n",
    "dot = Digraph(comment='Full Database Schema', format='png')\n",
    "dot.attr(rankdir='LR')  # Горизонтальная схема\n",
    "dot.attr('node', shape='plaintext')  # Таблицы как таблички\n",
    "\n",
    "# Создаем таблички с полями\n",
    "for table in tables:\n",
    "    table_df = df[df['Table'] == table]\n",
    "    fields = \"\"\n",
    "    for _, row in table_df.iterrows():\n",
    "        line = f\"{row['Field Name']} : {row['Data Type']}\"\n",
    "        if row['Primary Key']:\n",
    "            line += \" [PK]\"\n",
    "        if row['Foreign Key'] != \"None\":\n",
    "            line += f\" [FK → {row['Foreign Key']}]\"\n",
    "        if row['Indexed']:\n",
    "            line += \" [IDX]\"\n",
    "        fields += f\"<TR><TD ALIGN='LEFT'>{line}</TD></TR>\"\n",
    "\n",
    "    table_html = f\"\"\"<\n",
    "    <TABLE BORDER='1' CELLBORDER='0' CELLSPACING='0'>\n",
    "        <TR><TD BGCOLOR='lightgray'><B>{table}</B></TD></TR>\n",
    "        {fields}\n",
    "    </TABLE>\n",
    "    >\"\"\"\n",
    "    \n",
    "    dot.node(table, table_html)\n",
    "\n",
    "# Добавим связи между таблицами на основе Foreign Keys\n",
    "df_fk = df[df['Foreign Key'].notna() & (df['Foreign Key'] != 'None')]\n",
    "\n",
    "for _, row in df_fk.iterrows():\n",
    "    from_table = row['Table']\n",
    "    fk = row['Foreign Key']\n",
    "    \n",
    "    try:\n",
    "        to_table, _ = fk.strip(\")\").split(\"(\")\n",
    "        to_table = to_table.strip()\n",
    "        dot.edge(from_table, to_table, label=row['Field Name'])\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в Foreign Key '{fk}': {e}\")\n",
    "\n",
    "# Сохраняем как PNG и открываем\n",
    "dot.render('full_database_schema', cleanup=True)\n",
    "dot.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e7182-ab09-4d11-aa45-7abf395a153b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
